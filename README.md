# LunarLanderRl â€“ Deep Reinforcement Learning Agent mit Gymnasium

Dieses Projekt wurde im Rahmen des KISY-Unterrichts erstellt. Ziel ist es, einen Deep Q-Learning Agenten zu trainieren, der das Spiel **LunarLander-v3** mithilfe der Bibliothek **gymnasium** meistert.

---

## ğŸ—‚ï¸ Ordnerstruktur

```
LunarLanderRl/
â”‚
â”œâ”€â”€ main.py                 # Training des Agenten
â”œâ”€â”€ dqn_agent.py            # DQNAgent-Klasse mit Q-Network
â”œâ”€â”€ utils.py                # Plotfunktion fÃ¼r Rewards
â”œâ”€â”€ replay.py               # Spiel mit gespeichertem Modell wiedergeben
â”œâ”€â”€ features_demo.py        # Zeigt Spielzustand & Feature-Werte
â”œâ”€â”€ qvalue_demo.py          # Zeigt Q-Werte fÃ¼r fixen Zustand
â”œâ”€â”€ modell/                 # Gespeicherte Modelle (.pth)
â”œâ”€â”€ Gymnasium_Aufgabe.odt   # Word-Dokumentation
â””â”€â”€ reward_plot.png         # Automatisch generierter Trainingsplot
```

---

## ğŸ“¦ Installation

Voraussetzungen:

- Python 3.10 â€“ 3.12  
- Installation der Bibliotheken:

```bash
pip install gymnasium[box2d] torch matplotlib
```

---

## ğŸš€ Features (Inputs fÃ¼r das neuronale Netz)

Das Environment liefert 8 Zustandswerte:

1. Horizontale Position  
2. Vertikale Position  
3. Horizontale Geschwindigkeit  
4. Vertikale Geschwindigkeit  
5. Neigungswinkel  
6. Winkelgeschwindigkeit  
7. Kontakt linker FuÃŸ  
8. Kontakt rechter FuÃŸ  

Diese Features beschreiben die physikalische Lage des Landers vollstÃ¤ndig.

---

## ğŸ§  Training starten

```bash
python main.py
```

- FÃ¼hrt z.â€¯B. 10 Trainings-Episoden aus  
- Speichert das Modell in `modell/lunarlander_model.pth`  
- Zeichnet Rewards auf und erzeugt `reward_plot.png`

---

## ğŸ® Replay mit gespeichertem Modell

```bash
python replay.py
```

â†’ Gib bei der Eingabeaufforderung den Modellpfad ein, z.â€¯B.:

```
C:\...\LunarLanderRl\modell\lunarlander_model.pth
```

Der Agent spielt das Spiel basierend auf dem trainierten Q-Network.

---

## ğŸ” Beispielzustand & gewÃ¤hlte Aktion

```bash
python qvalue_demo.py
```

Zeigt:

- Einen Beispielzustand (state) mit 8 Werten  
- Die berechneten Q-Werte  
- Die vom Modell gewÃ¤hlte Aktion

---

## ğŸ“Š Feature-Demo & GUI

```bash
python features_demo.py
```

Zeigt:

- Die 8 Beobachtungswerte vom Environment  
- Das laufende Spiel im Fenster (env.render)  

---

